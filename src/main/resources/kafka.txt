## kafka has topics, partitions, cluster of brokers (up to 100)
## each partition has their own queue of messages with order. (message's place in order calls offset)
## kafka cluster has replication factor which determine how many copies of partitions will be created (good practice is 3)
## kafka replicas have strictly 1 leader and other replicas are just synced copies

## kafka has receive acknowledgement modes:
##    acks=0 - producer won't wait
##    acks=1 - producer will wait for leader acknowledgement
##    acks=all - producer will wait for leader and replicas acknowledgement

## producer can send key with message
## if key==null, messages go to partitions by round-robin
## messages with the same key will go to the same partition

## consumers are united in consumer groups
## 2 consumers can read 3 partitions (1-2 & 1-1), but if we have 3 consumers and 2 partitions - one consumer will be inactive
## each partition has consumer offset, which guarantees continuous reading if one of consumers will go down
## consumer chooses when to commit offset
##    - at most once (commit only when message is received, if error - message will not be read repeatedly)
##    - at least once (commit after message is processed, if error - message will be read repeatedly)
##    - exactly once (could be used only from kafka to kafka with Kafka Streams API)

## every kafka broker is called a 'bootstrap server'
## each broker knows about each other broker, each topic and each partition
## client is connecting, getting metadata and then connecting to required broker

## cluster managed by zookeeper

## after install we need to specify a directory for temporary zookeeper files for not using a default one. we can do it in config/zookeeper.properties relative to kafka dir
## to start zookeeper on linux from kafka folder. we need to specify a config for that in cmd
bin/zookeper-service-start.sh config/zookeeper.properties
## also we need to specify a directory for kafka logs for not using a default one. we can do it in config/server.properties file by specifying a log.dirs param
## command to launch kafka
kafka-server-start.sh config/server.properties
## command with help msg
kafka-topics
## create topic. partitions required, replication-factor required, replication-factor cannot be higher than count of available brokers
kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --create --partitions 3 --replication-factor 1
## watch list of topics
kafka-topics --zookeeper 127.0.0.1:2181 --list
## watch detail info about topic
kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --describe
## delete topic
kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --delete

## send message to kafka topic
kafka-console-producer --broker-list 127.0.0.1:9092 --topic first_topic
## additional params to send message cmd - '--producer-property acks=all' set acknowledge mode
## if we send msg to not existing topic - it will create with default params. we can change default count of partitions in service.properties, for example

## consume new messages since connect
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic
## consume all of topic messages
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning
## specify group for consumer
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --group example_group

## if to one topic connected 2 consumers of same group and 1 consumer without group - then all messages (for example, 5) will send by the next way:
## 5 messages will split to 2 consumers from group and another copy of 5 messages will be sent to consumer without group
## if one consumer will connect with group and will read messages from beginning and after that to topic will connect another consumer from the same group, the new consumer will not read anything, because messages to this group are already read

## list of created consumer groups at bootstrap server
kafka-consumer-groups --bootstrap-server localhost:9092 --list
## detail data about group with info about all of the consumers at each partition and topic and with all offsets
kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group example_group
## reset offsets for group (consumers should be inactive)
kafka-consumer-groups --bootstrap-server localhost:9092 --group example_group --reset-offsets --to-earliest --execute --topic first_topic

## create config commands for topics, brokers etc.
## see info about topic config
kafka-configs --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name {topic_name} --describe
## add config to a topic
kafka-configs --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name {topic_name} --add-config min.insync.replicas=2 --alter
## remove config from a topic
kafka-configs --zookeeper 127.0.0.1:2181 --entity-type topics --entity-name {topic_name} --delete-config min.insync.replicas --alter

## kafka ack params. this means that if 'acks=all', we will get response from broker when at lease 2 ISR (including leader) will say that they got data
min.insync.replicas=2
## param to parallel produce requests per partition. Default = 5. param as 1 for ordering can be used for kafka <= 1.1
max.in.flight.requests.per.connection

## kafka >= 0.11 has idempotent producer, which will not commint duplicate message if ack didn't went back in cause of network issues, for example. kafka is smart enough to read message id, which is already commited, not commit it again, but send ack back in second try
enable.idempotence=true

## 'safe producer' summary (can impact to latency):
## kafka < 0.11:
acks=all
min.insync.replicas=1
retries=MAX_INT
max.in.flight.requests.per.connection=1
## kafka >= 0.11. params below imply that acks=all, retries=MAX_INT, max.in.flight.requests.per.connection=5 (default value)
enable.idempotence=true
min.insync.replicas=2

## kafka message compression. next param has available values: ["none", "gzip", "lz4", "snappy"]. "none" is default. "snappy" is good for text and has good balance of CPU / compression ratio.
compression.type

## 'linger.ms' - number of ms which kafka will wait before send a batch. default is '0'. we can, for example, add 'linger.ms=5', we will not got a big amount of lags, but will increase a chance that kafka will wait for some additional messages for the batch and this way we are increasing the throughput.
## 'batch.size' - size of a batch (obviously :D). default is 16kb. advice from linkedin is to set batch size to 32 or 64 kb. batch size is setted by partition. value usually sets in bytes.

## producer can send messages faster than broker can take. then we can use the 'buffer.memory' which will collect messages to a buffer (obviously :D). default buffer size is 32 mb.
## if buffer is full, '.send()' method will block the producer. and here we can specify a 'max.block.ms' parameter which will set the block time for producer before getting an exception. default value is '60000'.

## consumer params:
## 'fetch.min.bytes' - minimum bytes for fetching on consumer poll event. can increase to increase throughput. default value 1
## 'max.poll.records' - maximum messages for one poll. default 500. can increase if messages are very small
## 'max.partitions.fetch.bytes' - obviously. default 1mb
## 'fetch.max.bytes' - obviously. default 50mb
## 'enable.auto.commit' - true or false. if false - we could commit offsets manually. true is default
## 'offset.retention.minutes' - time after which disconnected consumers will lost their offsets
## 'session.timeout.ms' - consumer heartbeat delay before disconnect. default 10 sec
## 'heartbeat.interval.ms' - obviously. default 3 sec
## 'max.poll.interval.ms' - max interval before polls to understand that consumer is dead. default 5 min

## partition params:
## 'log.segment.bytes' - size of log segment. default 1gb
## 'log.segment.ms' - time after which partition will create new log, in in duration of this time no new records arrived to opened segment. default 1 week

## kafka cleanup
## 'log.cleanup.policy' - cleaning strategy. default = delete. deleting based on age of data. default - week. and based on a size of a log. default is '-1' which equals infinite
## policy 'compact' used for offsets topics. delete based on keys. delete duplicates after the active segment is committed. compact policy holds last version of value for each key, a.k.a. snapshot. 'delete.retention.ms' - time on which consumers still see deleted messages, which marked for delete. 'min.cleanable.dirty.ratio' default 0.5 - how often call compaction
## cleaner checks for work for every 15 seconds by default. 'log.cleaner.backoff.ms'
## 'log.retention.hours' - number of hours to keep data for. default 168 (week)
## 'log.retention.bytes' - max bytes of data for each partition. default '-1'. if set to fixed value - we will have rotating files with data. deleting older, creating newer.
