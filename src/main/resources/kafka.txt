## kafka has topics, partitions, cluster of brokers (up to 100)
## each partition has their own queue of messages with order. (message's place in order calls offset)
## kafka cluster has replication factor which determine how many copies of partitions will be created (good practice is 3)
## kafka replicas have strictly 1 leader and other replicas are just synced copies

## kafka has receive acknowledgement modes:
##    acks=0 - producer won't wait
##    acks=1 - producer will wait for leader acknowledgement
##    acks=all - producer will wait for leader and replicas acknowledgement

## producer can send key with message
## if key==null, messages go to partitions by round-robin
## messages with the same key will go to the same partition

## consumers are united in consumer groups
## 2 consumers can read 3 partitions (1-2 & 1-1), but if we have 3 consumers and 2 partitions - one consumer will be inactive
## each partition has consumer offset, which guarantees continuous reading if one of consumers will go down
## consumer chooses when to commit offset
##    - at most once (commit only when message is received, if error - message will not be read repeatedly)
##    - at least once (commit after message is processed, if error - message will be read repeatedly)
##    - exactly once (could be used only from kafka to kafka with Kafka Streams API)

## every kafka broker is called a 'bootstrap server'
## each broker knows about each other broker, each topic and each partition
## client is connecting, getting metadata and then connecting to required broker

## cluster managed by zookeeper

## after install we need to specify a directory for temporary zookeeper files for not using a default one. we can do it in config/zookeeper.properties relative to kafka dir
## to start zookeeper on linux from kafka folder. we need to specify a config for that in cmd
bin/zookeper-service-start.sh config/zookeeper.properties
## also we need to specify a directory for kafka logs for not using a default one. we can do it in config/server.properties file by specifying a log.dirs param
## command to launch kafka
kafka-server-start.sh config/server.properties
## command with help msg
kafka-topics
## create topic. partitions required, replication-factor required, replication-factor cannot be higher than count of available brokers
kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --create --partitions 3 --replication-factor 1
## watch list of topics
kafka-topics --zookeeper 127.0.0.1:2181 --list
## watch detail info about topic
kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --describe
## delete topic
kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --delete

## send message to kafka topic
kafka-console-producer --broker-list 127.0.0.1:9092 --topic first_topic
## additional params to send message cmd - '--producer-property acks=all' set acknowledge mode
## if we send msg to not existing topic - it will create with default params. we can change default count of partitions in service.properties, for example

## consume new messages since connect
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic
## consume all of topic messages
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --from-beginning
## specify group for consumer
kafka-console-consumer --bootstrap-server 127.0.0.1:9092 --topic first_topic --group example_group

## if to one topic connected 2 consumers of same group and 1 consumer without group - then all messages (for example, 5) will send by the next way:
## 5 messages will split to 2 consumers from group and another copy of 5 messages will be sent to consumer without group
## if one consumer will connect with group and will read messages from beginning and after that to topic will connect another consumer from the same group, the new consumer will not read anything, because messages to this group are already read

## list of created consumer groups at bootstrap server
kafka-consumer-groups --bootstrap-server localhost:9092 --list
## detail data about group with info about all of the consumers at each partition and topic and with all offsets
kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group example_group
## reset offsets for group (consumers should be inactive)
kafka-consumer-groups --bootstrap-server localhost:9092 --group example_group --reset-offsets --to-earliest --execute --topic first_topic
